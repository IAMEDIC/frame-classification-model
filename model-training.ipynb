{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4712225b",
   "metadata": {},
   "source": [
    "# Frame Classification Model for Fetal Anatomic Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c53cb",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3133a",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342df543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:47:36.237440Z",
     "start_time": "2025-09-12T12:47:27.403155Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Optional, Iterator\n",
    "import hashlib\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.models.mobilenetv2 import MobileNet_V2_Weights\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mlflow\n",
    "from mlflow.data.dataset import Dataset as MLFLowDataset\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e1aaa",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1edc686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:47:48.385302Z",
     "start_time": "2025-09-12T12:47:48.376384Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51a8c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:47:50.898798Z",
     "start_time": "2025-09-12T12:47:50.840526Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b5339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:47:53.957585Z",
     "start_time": "2025-09-12T12:47:53.954226Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18b5ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:47:54.702977Z",
     "start_time": "2025-09-12T12:47:54.693625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Configuraton\n",
    "TARGET_HEIGHT = 224\n",
    "TARGET_WIDTH = 224\n",
    "# Dataset Configuration\n",
    "DATASET_DIR = os.getenv(\"DATASET_DIR\")\n",
    "TRUE_LABELS_DIR = \"Standard\"\n",
    "FALSE_LABELS_DIR = \"Non Standard\"\n",
    "VERSIONING_FILE_NAME = \"Versioning.xlsx\"\n",
    "VERSIONING_PATH = os.path.join(*[DATASET_DIR, VERSIONING_FILE_NAME])\n",
    "DATASET_VERSION = \"V1\"\n",
    "DATASET_TRAIN_VAL_COL = \"Train + Val Filenames\"\n",
    "DATASET_TEST_COL = \"Test Filenames\"\n",
    "# Experiment logging\n",
    "MLFLOW_URI = os.getenv(\"MLFLOW_URI\")\n",
    "MLFLOW_EXPERIMENT_NAME = f\"Frame_Classifier_{TARGET_HEIGHT}x{TARGET_WIDTH}\"\n",
    "MLFLOW_USER = os.getenv(\"MLFLOW_USER\")\n",
    "MODEL_NAME = f\"frame_classifier_{TARGET_HEIGHT}x{TARGET_WIDTH}\"\n",
    "TB_LOG_DIR = r\"./tb_logs\"\n",
    "# Training parameters\n",
    "TRAIN_SPLIT, VAL_SPLIT = 0.8, 0.2\n",
    "K_FOLDS = 5\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "# Temp dirs\n",
    "CHECKPOINTS_DIR = r\"./checkpoints\"\n",
    "if not os.path.exists(CHECKPOINTS_DIR):\n",
    "    os.makedirs(CHECKPOINTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e9d20",
   "metadata": {},
   "source": [
    "### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6524231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:48:06.180516Z",
     "start_time": "2025-09-12T12:48:06.016127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logging with tensorboard and mlflow\n",
    "if not os.path.exists(TB_LOG_DIR):\n",
    "    os.makedirs(TB_LOG_DIR, exist_ok=True)\n",
    "TB_WRITER = SummaryWriter(log_dir=TB_LOG_DIR)\n",
    "if MLFLOW_URI is None:\n",
    "    raise RuntimeError(\"MLFLOW_URI environment variable is not set.\")\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "MLFLOW_EXPERIMENT = mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd58d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:48:07.275321Z",
     "start_time": "2025-09-12T12:48:07.170270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup device\n",
    "DEVICE = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "# check if windows is being used and try to import torch-directml\n",
    "elif os.name == 'nt':\n",
    "    try:\n",
    "        import torch_directml\n",
    "        DEVICE = torch_directml.device()\n",
    "    except ImportError:\n",
    "        # type: ignore\n",
    "        try:\n",
    "            ! pip install torch-directml==0.2.4.dev240913\n",
    "            import torch_directml\n",
    "            DEVICE = torch_directml.device()\n",
    "        except Exception as e: # pylint: disable=broad-except\n",
    "            raise e\n",
    "    except Exception as e: # pylint: disable=broad-except\n",
    "        print(f\"Error occurred while setting up DirectML: {e}\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c70be8",
   "metadata": {},
   "source": [
    "## Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a55fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS: dict[str, set[str]] = {\n",
    "    TRUE_LABELS_DIR: set(),\n",
    "    FALSE_LABELS_DIR: set()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19782ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_name in [TEST_SET_DIR, TRAIN_VAL_SET_DIR]:\n",
    "    for label in [TRUE_LABELS_DIR, FALSE_LABELS_DIR]:\n",
    "        full_dir = os.path.join(dir_name, label)\n",
    "        if not os.path.exists(full_dir):\n",
    "            raise FileNotFoundError(f\"Directory {full_dir} does not exist.\")\n",
    "        ANNOTATIONS[label].update(os.listdir(full_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955a109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:48:11.368090Z",
     "start_time": "2025-09-12T12:48:11.364344Z"
    }
   },
   "outputs": [],
   "source": [
    "VERSIONING_DF = pd.read_excel(VERSIONING_PATH, sheet_name=DATASET_VERSION)\n",
    "TRAIN_VAL_IMG_NAMES = VERSIONING_DF[DATASET_TRAIN_VAL_COL].dropna().tolist()\n",
    "TEST_IMG_NAMES = VERSIONING_DF[DATASET_TEST_COL].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a68a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:48:12.807369Z",
     "start_time": "2025-09-12T12:48:12.802033Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_TRANSFORMS = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.Affine(rotate=(-15, 15), p=0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35945e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T12:48:13.723087Z",
     "start_time": "2025-09-12T12:48:13.708109Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AnatomyDatasetData():\n",
    "    images: NDArray[np.float32]\n",
    "    labels: NDArray[np.float32]\n",
    "\n",
    "\n",
    "class AnatomyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_dir: str,\n",
    "        img_names: Optional[list[str]] = None,\n",
    "    ):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = sorted(os.listdir(img_dir)) if img_names is None else img_names\n",
    "        self.n_imgs = len(self.img_names)\n",
    "        self.data: AnatomyDatasetData = AnatomyDatasetData(\n",
    "            images=np.zeros((self.n_imgs, TARGET_HEIGHT, TARGET_WIDTH), dtype=np.float32),\n",
    "            labels=np.zeros(self.n_imgs, dtype=np.float32)\n",
    "        )\n",
    "        self.load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_imgs\n",
    "    \n",
    "    def load_data(self):\n",
    "        for index, fname in enumerate(self.img_names):\n",
    "            img_class = TRUE_LABELS_DIR if fname in ANNOTATIONS[TRUE_LABELS_DIR] else FALSE_LABELS_DIR\n",
    "            img_path = os.path.join(*[self.img_dir, img_class, fname])\n",
    "            image = np.array(Image.open(img_path).convert('L'), dtype=np.float32)\n",
    "            image = A.Compose([\n",
    "                A.Resize(height=TARGET_HEIGHT, width=TARGET_WIDTH),\n",
    "                A.Normalize(mean=(0.5,), std=(0.5,), max_pixel_value=255.0),\n",
    "            ])(image=image)['image'] # Does not affect yolo format bboxes\n",
    "            self.data.images[index] = image\n",
    "            self.data.labels[index] = 1 if img_class == TRUE_LABELS_DIR else 0\n",
    "\n",
    "    def get_data(self, idx) -> tuple[np.ndarray, np.float32]:\n",
    "        return (\n",
    "            self.data.images[idx],\n",
    "            self.data.labels[idx]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return (\n",
    "            torch.tensor(self.data.images[idx]).unsqueeze(0),\n",
    "            torch.tensor(self.data.labels[idx])\n",
    "        )\n",
    "    \n",
    "    def get_class_balance(self) -> dict[str, int]:\n",
    "        class_counts = defaultdict(int)\n",
    "        for label in self.data.labels:\n",
    "            if label == 1:\n",
    "                class_counts[TRUE_LABELS_DIR] += 1\n",
    "            else:\n",
    "                class_counts[FALSE_LABELS_DIR] += 1\n",
    "        return dict(class_counts)\n",
    "\n",
    "\n",
    "class AnatomyDatasetSubset(AnatomyDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_dataset: AnatomyDataset,\n",
    "            indices: list[int] | NDArray[np.integer],\n",
    "            transform: Optional[A.Compose] = None,\n",
    "        ):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform = transform if transform is not None else A.NoOp()\n",
    "        self.indices = indices\n",
    "        self.img_names = [self.base_dataset.img_names[i] for i in self.indices]\n",
    "        self.n_imgs = len(self.indices)\n",
    "        self.data: AnatomyDatasetData = AnatomyDatasetData(\n",
    "            images=np.zeros((self.n_imgs, TARGET_HEIGHT, TARGET_WIDTH), dtype=np.float32\n",
    "            ),\n",
    "            labels=np.zeros(self.n_imgs, dtype=np.float32)\n",
    "        )\n",
    "        for new_index, original_index in enumerate(self.indices):\n",
    "            label = self.base_dataset.data.labels[original_index]\n",
    "            self.data.labels[new_index] = label\n",
    "        self.transform_data()\n",
    "    \n",
    "    def transform_data(self):\n",
    "        for new_index, original_index in enumerate(self.indices):\n",
    "            image = self.base_dataset.data.images[original_index]\n",
    "            transformed_image = self.transform(image=image)['image']\n",
    "            self.data.images[new_index] = transformed_image\n",
    "\n",
    "    def __iter__(self) -> Iterator[tuple[torch.Tensor, torch.Tensor]]:\n",
    "        for idx in range(len(self)):\n",
    "            yield self[idx]\n",
    "        self.transform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageListDataset(MLFLowDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            names: list[str],\n",
    "            source: str = VERSIONING_FILE_NAME,\n",
    "            version: str = DATASET_VERSION\n",
    "        ):\n",
    "        self._names = names\n",
    "        self._source = source\n",
    "        self._version = version\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"name\": \"image_list_dataset\",\n",
    "            \"digest\": hashlib.md5(\",\".join(self._names).encode()).hexdigest(),\n",
    "            \"source_type\": \"inline\",\n",
    "            \"source\": self._source,\n",
    "            \"schema\": None,\n",
    "            \"profile\": json.dumps({\n",
    "                \"version\": self._version,\n",
    "                \"num_images\": len(self._names),\n",
    "                \"filenames\": self._names\n",
    "            }),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136ae97",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-09-12T12:48:14.741067Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_VAL_DATASET = AnatomyDataset(\n",
    "    img_dir=DATASET_DIR,\n",
    "    img_names=TRAIN_VAL_IMG_NAMES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATASET = AnatomyDataset(\n",
    "    img_dir=DATASET_DIR,\n",
    "    img_names=TEST_IMG_NAMES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train + Val class balance:\", TRAIN_VAL_DATASET.get_class_balance())\n",
    "print(\"Test class balance:\", TEST_DATASET.get_class_balance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(\n",
    "        dataset: AnatomyDataset,\n",
    "        idxs: list[int]):\n",
    "    fig, axs = plt.subplots(1, len(idxs), figsize=(10, 10), num=\"Dataset Sample\")\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = np.array([axs])\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img, label = dataset[idx]\n",
    "        img = img.squeeze(0).numpy()  # Convert to 2D array\n",
    "        img_name = dataset.img_names[idx]\n",
    "        ax = axs[i] if len(idxs) > 1 else axs\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"{img_name}\\nLabel: {TRUE_LABELS_DIR if label.item() == 1 else FALSE_LABELS_DIR}\")\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5648f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 3 images from TRAIN_VAL_DATASET\n",
    "indices = np.random.choice(len(TRAIN_VAL_DATASET), size=3, replace=False)\n",
    "visualize_sample(TRAIN_VAL_DATASET, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc28633",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHead(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        # Classifier head: Binary classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        probs = self.classifier(features)                       # [B, 1]\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetusAnatomyFrameClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load pretrained MobileNetV2 and adapt for 1 channel\n",
    "        mobilenet = models.mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        self.features = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # Modify first conv layer to accept grayscale\n",
    "        first_conv = self.features[0][0]\n",
    "        new_conv = nn.Conv2d(1, first_conv.out_channels, kernel_size=first_conv.kernel_size,\n",
    "                             stride=first_conv.stride, padding=first_conv.padding, bias=False)\n",
    "        new_conv.weight.data = first_conv.weight.data.mean(dim=1, keepdim=True)\n",
    "        self.features[0][0] = new_conv\n",
    "        # Head\n",
    "        self.head = DetectionHead(in_features=1280)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)                    # [B, 1280, H', W']\n",
    "        x = self.pool(x).view(x.size(0), -1)    # [B, 1280]\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228aa0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_loss(\n",
    "        pred_probs: torch.Tensor,\n",
    "        gt_probs: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Combined loss for multi-label classification and bounding box regression.\n",
    "    \"\"\"\n",
    "    bce_loss_fn = nn.BCELoss()\n",
    "    cls_loss = bce_loss_fn(pred_probs, gt_probs.unsqueeze(1))\n",
    "    total_loss = cls_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd5e10",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa93ad",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    preds = (preds >= 0.5).float()\n",
    "    correct = (preds == labels).float()\n",
    "    return correct.sum() / len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec183c1f",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaada1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: FetusAnatomyFrameClassifier,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer # type: ignore\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch.\n",
    "    Args:\n",
    "        model: The neural network model to train.\n",
    "        dataloader: DataLoader providing training data batches.\n",
    "        optimizer: Optimizer for updating model parameters.\n",
    "    Returns:\n",
    "        Average training loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_tqdm = tqdm(train_dataloader, desc=\"Training batches\", leave=False, position=2)\n",
    "    for batch in batch_tqdm:\n",
    "        imgs: torch.Tensor = batch[0]\n",
    "        labels: torch.Tensor = batch[1]\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        cls_pred = model(imgs)\n",
    "        loss = detection_loss(cls_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    batch_tqdm.close()\n",
    "    return total_loss / len(train_dataloader)\n",
    "\n",
    "def validate(\n",
    "    model: FetusAnatomyFrameClassifier,\n",
    "    val_loader: DataLoader,\n",
    "    epoch: Optional[int] = None\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on the validation set.\n",
    "    Args:\n",
    "        model: The neural network model to evaluate.\n",
    "        val_loader: DataLoader providing validation data batches.\n",
    "        epoch: Current epoch number (for logging).\n",
    "    Returns:\n",
    "        Tuple of (mean validation loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    pred_classes = torch.zeros(len(val_loader.dataset), dtype=torch.float32)\n",
    "    labels = torch.zeros(len(val_loader.dataset), dtype=torch.float32)\n",
    "    current_index = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            imgs: torch.Tensor = batch[0]                   # [B, 1, H, W]\n",
    "            batch_labels: torch.Tensor = batch[1]                 # [B]\n",
    "            batch_size = batch_labels.size(0)\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            batch_pred_classes: torch.Tensor = model(imgs)            # [B, 1]\n",
    "            loss = detection_loss(batch_pred_classes, batch_labels.to(DEVICE))\n",
    "            total_loss += loss.item()\n",
    "            pred_classes[current_index:current_index + batch_size] = (batch_pred_classes.squeeze().cpu() >= 0.5).float()\n",
    "            labels[current_index:current_index + batch_size] = batch_labels.cpu()\n",
    "            current_index += batch_size\n",
    "    acc = accuracy(pred_classes, labels)\n",
    "    mean_loss = total_loss / len(val_loader)\n",
    "    if epoch is not None:\n",
    "        TB_WRITER.add_scalar(\"val/loss\", mean_loss, epoch)\n",
    "        TB_WRITER.add_scalar(\"val/accuracy\", acc, epoch)\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(\n",
    "    model_constructor: type[FetusAnatomyFrameClassifier],\n",
    "    train_subset: AnatomyDatasetSubset,\n",
    "    val_subset: AnatomyDatasetSubset,\n",
    "    checkpoint_path: str,\n",
    "    fold_idx: int,\n",
    "    n_epochs: int,\n",
    "    batch_size: int,\n",
    "    learning_rate: float,\n",
    "    weight_decay: float,\n",
    "    early_stopping_patience: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Trains the model on one fold of the dataset.\n",
    "    Args:\n",
    "        model_constructor: Constructor for the model to train.\n",
    "        train_subset: Training subset of the dataset.\n",
    "        val_subset: Validation subset of the dataset.\n",
    "        checkpoint_path: Path to save the best model checkpoint.\n",
    "        fold_idx: Index of the current fold (for logging).\n",
    "        n_epochs: Number of epochs to train.\n",
    "        batch_size: Batch size for training.\n",
    "        learning_rate: Learning rate for the optimizer.\n",
    "        weight_decay: Weight decay (L2 regularization) for the optimizer.\n",
    "        early_stopping_patience: Number of epochs with no improvement to wait before stopping.\n",
    "    Returns:\n",
    "        Best validation accuracy achieved during training.\n",
    "    \"\"\"\n",
    "    # Start MLflow run for the entire training process\n",
    "    # MLFlow run setup\n",
    "    mlflow_run_id = None\n",
    "    active_run = mlflow.active_run()\n",
    "    if active_run is not None:\n",
    "        mlflow_run_id = active_run.info.run_id\n",
    "    if mlflow_run_id is not None:\n",
    "        mlflow.log_params({\n",
    "            \"num_epochs\": n_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"model_type\": \"FetusAnatomyFrameClassifier\",\n",
    "            \"backbone\": \"MobileNetV2\"\n",
    "        }, run_id=mlflow_run_id)\n",
    "    # Initialization\n",
    "    model = model_constructor().to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # type: ignore\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "    train_dataloader = DataLoader(train_subset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    epoch_tqdm = tqdm(range(n_epochs), desc=f\"Fold {fold_idx + 1} - Epochs\", position=1, leave=True)\n",
    "    for epoch in epoch_tqdm:\n",
    "        # Training\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer)\n",
    "        # Validation\n",
    "        val_loss, val_acc = validate(model, val_dataloader, epoch)\n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        # Log to TensorBoard\n",
    "        TB_WRITER.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "        TB_WRITER.add_scalar(\"train/learning_rate\", current_lr, epoch)\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        # Log metrics to MLflow\n",
    "        if mlflow_run_id is not None:\n",
    "            mlflow.log_metrics({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"learning_rate\": current_lr\n",
    "            }, step=epoch, run_id=mlflow_run_id)\n",
    "        # Save checkpoint if we have a better model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        # Early stopping check\n",
    "        epoch_description = \\\n",
    "            f\"Fold {fold_idx + 1} - \"\\\n",
    "            f\"Train Loss: {train_loss:.2f} - \" \\\n",
    "            f\"Val Loss: {val_loss:.2f} - \"\\\n",
    "            f\"Val Acc: {val_acc:.2f} - \"\\\n",
    "            f\"LR: {current_lr} - Epochs\"\n",
    "        epoch_tqdm.set_description(epoch_description)\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            break\n",
    "        # Re-augment training data for next epoch\n",
    "        train_subset.transform_data()\n",
    "    if mlflow_run_id is not None:\n",
    "        mlflow.log_metrics({\n",
    "            \"final_val_loss\": val_loss,\n",
    "            \"final_val_acc\": val_acc,\n",
    "            \"best_val_acc\": best_val_acc\n",
    "        }, run_id=mlflow_run_id)\n",
    "        dummy_input = torch.randn(1, 1, TARGET_HEIGHT, TARGET_WIDTH)\n",
    "        export_path = checkpoint_path.replace(\".pth\", \".onnx\")\n",
    "        saved_model = model_constructor()\n",
    "        saved_model.load_state_dict(torch.load(checkpoint_path))\n",
    "        torch.onnx.export(\n",
    "            saved_model.cpu(),\n",
    "            dummy_input,\n",
    "            export_path,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            opset_version=11,\n",
    "            dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "        )\n",
    "        mlflow.log_artifact(export_path, run_id=mlflow_run_id)\n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy_context:\n",
    "    def __init__(self, *args, **kwargs):  # Accept any arguments\n",
    "        pass\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        pass\n",
    "\n",
    "def train(\n",
    "    model_constructor: type[FetusAnatomyFrameClassifier],\n",
    "    dataset: AnatomyDataset,\n",
    "    train_split: float,\n",
    "    val_split: float,\n",
    "    log_runs_to_mlflow: bool,\n",
    "    n_epochs: int,\n",
    "    batch_size: int,\n",
    "    k_folds: int,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    early_stopping_patience: int\n",
    ") -> tuple[str, Optional[mlflow.ActiveRun]]:\n",
    "    \"\"\"\n",
    "    Train the model using the specified parameters.\n",
    "    \"\"\"\n",
    "    if log_runs_to_mlflow:\n",
    "        context = mlflow.start_run\n",
    "    else:\n",
    "        context = dummy_context\n",
    "    base_run_name = f\"{MLFLOW_USER}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    n_images = len(dataset)\n",
    "    train_start, train_end = 0, int(train_split * n_images)\n",
    "    val_start, val_end = train_end, int((train_split + val_split) * n_images) if (train_split + val_split) < 1.0 else n_images\n",
    "    check_points_paths = []\n",
    "    runs = []\n",
    "    validation_accs = []\n",
    "    folds_tqdm = tqdm(range(k_folds), desc=\"Folds\", leave=True, position=0)\n",
    "    for fold in folds_tqdm:\n",
    "        run_name = f\"{base_run_name}_fold_{fold + 1}\"\n",
    "        with context(run_name=run_name) as run:\n",
    "            runs.append(run)\n",
    "            checkpoint_path=os.path.join(CHECKPOINTS_DIR, f\"{run_name}.pth\")\n",
    "            check_points_paths.append(checkpoint_path)\n",
    "            shuffled_indices = np.random.permutation(np.arange(n_images))\n",
    "            train_indices = shuffled_indices[train_start:train_end]\n",
    "            val_indices = shuffled_indices[val_start:val_end]\n",
    "            train_subset = AnatomyDatasetSubset(\n",
    "                base_dataset=dataset,\n",
    "                indices=train_indices,\n",
    "                transform=TRAIN_TRANSFORMS\n",
    "            )\n",
    "            val_subset = AnatomyDatasetSubset(\n",
    "                base_dataset=dataset,\n",
    "                indices=val_indices,\n",
    "                transform=None\n",
    "            )\n",
    "            if run_name is not None:\n",
    "                mlflow.log_input(\n",
    "                    ImageListDataset(\n",
    "                        names=train_subset.img_names,\n",
    "                        version=DATASET_VERSION,\n",
    "                        source=VERSIONING_FILE_NAME\n",
    "                    ),\n",
    "                    context=\"Train Set\"\n",
    "                )\n",
    "                mlflow.log_input(\n",
    "                    ImageListDataset(\n",
    "                        names=val_subset.img_names,\n",
    "                        version=DATASET_VERSION,\n",
    "                        source=VERSIONING_FILE_NAME\n",
    "                    ),\n",
    "                    context=\"Validation Set\"\n",
    "                )\n",
    "            val_acc = train_one_fold(\n",
    "                model_constructor=model_constructor,\n",
    "                train_subset=train_subset,\n",
    "                val_subset=val_subset,\n",
    "                checkpoint_path=checkpoint_path,\n",
    "                fold_idx = fold,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                weight_decay=weight_decay,\n",
    "                early_stopping_patience=early_stopping_patience\n",
    "            )\n",
    "            validation_accs.append(val_acc)\n",
    "            best_fold = np.argmax(validation_accs)\n",
    "            folds_tqdm.set_description(f\"Best fold: {best_fold + 1}, with accuracy: {validation_accs[best_fold]:.3f} - Folds\")\n",
    "    best_fold = np.argmax(validation_accs)\n",
    "    return check_points_paths[best_fold], runs[best_fold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d7d6e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fcdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_checkpoint_path, best_run = train(\n",
    "    model_constructor=FetusAnatomyFrameClassifier,\n",
    "    dataset=TRAIN_VAL_DATASET,\n",
    "    log_runs_to_mlflow=True,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    k_folds=K_FOLDS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "    train_split=TRAIN_SPLIT,\n",
    "    val_split=VAL_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d65d5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = FetusAnatomyFrameClassifier().to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(best_model_checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0192cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_prediction(\n",
    "        model: FetusAnatomyFrameClassifier,\n",
    "        dataset: AnatomyDataset,\n",
    "        idxs: list[int]\n",
    "    ):\n",
    "    fig, axs = plt.subplots(1, len(idxs), figsize=(4 * len(idxs), 4), num=\"Dataset Prediction Visualization\")\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = np.array([axs])\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img, label = dataset[idx]\n",
    "        pred: torch.Tensor = model(img.unsqueeze(0).to(DEVICE))\n",
    "        print(f\"Predicted probability: {pred.item():.4f}\")\n",
    "        pred_label = TRUE_LABELS_DIR if pred.item() >= 0.5 else FALSE_LABELS_DIR\n",
    "        img = img.squeeze(0).numpy()  # Convert to 2D array\n",
    "        img_name = dataset.img_names[idx]\n",
    "        ax: plt.Axes = axs[i] if len(idxs) > 1 else axs\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"{img_name}\\nLabel: {TRUE_LABELS_DIR if label.item() == 1 else FALSE_LABELS_DIR}\\nPrediction: {pred_label} ({pred.item():.2f})\")\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.choice(len(TEST_DATASET), size=5, replace=False)\n",
    "visualize_prediction(best_model, TEST_DATASET, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(TEST_DATASET, BATCH_SIZE, False, num_workers=0, pin_memory=True)\n",
    "mean_test_loss, mean_test_acc = validate(best_model, test_dl)\n",
    "print(f\"Mean Test Loss: {mean_test_loss:.2f}\")\n",
    "print(f\"Mean Test accuracy: {mean_test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934025ee",
   "metadata": {},
   "source": [
    "## Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_run is not None:\n",
    "    artifact_name = best_model_checkpoint_path.replace(\".pth\", \".onnx\").split(os.sep)[-1]\n",
    "    model_version = mlflow.register_model(\n",
    "        model_uri=f\"{MLFLOW_EXPERIMENT.artifact_location}/{best_run.info.run_id}/artifacts/{artifact_name}\",\n",
    "        name=MODEL_NAME\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
